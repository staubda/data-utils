{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data from disk\n",
    "with open('/home/david/datasets/coco/val2017/annotations/instances_val2017.json', 'r') as fp:\n",
    "    val_instances = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotation info into dataframe\n",
    "# box coordinates [x,y,width,height] are measured from the top left image corner and are 0-indexed\n",
    "df_ann = (\n",
    "    pd.DataFrame(val_instances['annotations'])\n",
    "    .drop(columns=['segmentation', 'area'])\n",
    "    .rename(columns={'id': 'instance_id'})\n",
    ")\n",
    "df_ann['bbox_x'] = df_ann['bbox'].str[0]\n",
    "df_ann['bbox_y'] = df_ann['bbox'].str[1]\n",
    "df_ann['bbox_width'] = df_ann['bbox'].str[2]\n",
    "df_ann['bbox_height'] = df_ann['bbox'].str[3]\n",
    "\n",
    "# Load category info into dataframe\n",
    "df_cat = (\n",
    "    pd.DataFrame(val_instances['categories'])\n",
    "    .drop(columns=['supercategory'])\n",
    "    .rename(columns={'id': 'category_id', 'name': 'category_name'})\n",
    ")\n",
    "\n",
    "# Combine all info into single dataframe\n",
    "df_comb = pd.merge(df_ann, df_cat, on='category_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose categories to consider, implicitly indicating which should have missing instances\n",
    "dataset1_cats = {'person', 'car', 'book', 'cup', 'dining table'}\n",
    "dataset2_cats = {'person', 'chair', 'bottle', 'cup', 'dining table'}\n",
    "dataset3_cats = dataset1_cats | dataset2_cats\n",
    "\n",
    "# Assign images to differnet halves of dataset with missing annotations\n",
    "np.random.seed(0)\n",
    "image_ids = df_comb['image_id'].unique()\n",
    "image_id_dataset_mask = np.random.randint(0, 2, len(image_ids)).astype(bool)\n",
    "image_ids_dataset1 = set(image_ids[image_id_dataset_mask].tolist())\n",
    "image_ids_dataset2 = set(image_ids[~image_id_dataset_mask].tolist())\n",
    "is_dataset1_image = df_comb['image_id'].isin(image_ids_dataset1)\n",
    "is_dataset2_image = df_comb['image_id'].isin(image_ids_dataset2)\n",
    "\n",
    "# Identify instances belonging to valid categories\n",
    "is_dataset1_cat = df_comb['category_name'].isin(dataset1_cats)\n",
    "is_dataset2_cat = df_comb['category_name'].isin(dataset2_cats)\n",
    "is_dataset3_cat = df_comb['category_name'].isin(dataset3_cats)\n",
    "\n",
    "# Identify valid instances for two halves of dataset with partial annotations\n",
    "is_dataset1_instance = is_dataset1_image & is_dataset1_cat\n",
    "is_dataset2_instance = is_dataset2_image & is_dataset2_cat\n",
    "is_dataset12_instance = is_dataset1_instance | is_dataset2_instance\n",
    "\n",
    "# Identify valid instances for dataset with complete annotations\n",
    "image_ids_dataset12 = set(df_comb.loc[is_dataset12_instance, 'image_id'].tolist())\n",
    "is_dataset3_image = df_comb['image_id'].isin(image_ids_dataset12)\n",
    "is_dataset3_instance = is_dataset3_image & is_dataset3_cat\n",
    "\n",
    "# Create dataframes for datasets with partial and complete annotations\n",
    "df_dataset12 = df_comb[is_dataset12_instance]\n",
    "df_dataset3 = df_comb[is_dataset3_instance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 1 - num images: 1681, num instances: 7986\n",
      "dataset 2 - num images: 1590, num instances: 7503\n",
      "dataset 3 - num images: 3271, num instances: 17919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset1</th>\n",
       "      <th>dataset2</th>\n",
       "      <th>dataset3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>5630</td>\n",
       "      <td>5374</td>\n",
       "      <td>11004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chair</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>802</td>\n",
       "      <td>1712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>915</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>583</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottle</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>589</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cup</th>\n",
       "      <td>465</td>\n",
       "      <td>434</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dining table</th>\n",
       "      <td>393</td>\n",
       "      <td>304</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset1  dataset2  dataset3\n",
       "person            5630      5374     11004\n",
       "chair             <NA>       802      1712\n",
       "car                915      <NA>      1650\n",
       "book               583      <NA>      1020\n",
       "bottle            <NA>       589       937\n",
       "cup                465       434       899\n",
       "dining table       393       304       697"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get total instance and image counts\n",
    "num_images1 = df_comb.loc[is_dataset1_instance, 'image_id'].nunique()\n",
    "num_images2 = df_comb.loc[is_dataset2_instance, 'image_id'].nunique()\n",
    "num_images3 = df_comb.loc[is_dataset3_instance, 'image_id'].nunique()\n",
    "print(f'dataset 1 - num images: {num_images1}, num instances: {is_dataset1_instance.sum()}')\n",
    "print(f'dataset 2 - num images: {num_images2}, num instances: {is_dataset2_instance.sum()}')\n",
    "print(f'dataset 3 - num images: {num_images3}, num instances: {is_dataset3_instance.sum()}')\n",
    "\n",
    "# Get per category instance counts \n",
    "pd.concat(\n",
    "    [\n",
    "        df_comb.loc[is_dataset1_instance, 'category_name'].value_counts().rename('dataset1'),\n",
    "        df_comb.loc[is_dataset2_instance, 'category_name'].value_counts().rename('dataset2'),\n",
    "        df_comb.loc[is_dataset3_instance, 'category_name'].value_counts().rename('dataset3'),\n",
    "    ],\n",
    "    axis=1\n",
    ").sort_values(by='dataset3', ascending=False).astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split datasets into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split parameters\n",
    "train_frac = 0.7\n",
    "val_frac = 0.1\n",
    "np.random.seed(0)\n",
    "\n",
    "# Assign images to different splits\n",
    "num_train = round(len(image_ids) * train_frac)\n",
    "num_val = round(len(image_ids) * val_frac)\n",
    "image_ids_shuffle = np.random.permutation(image_ids)\n",
    "image_ids_train = set(image_ids_shuffle[:num_train].tolist())\n",
    "image_ids_val = set(image_ids_shuffle[num_train:num_train+num_val].tolist())\n",
    "image_ids_test = set(image_ids_shuffle[num_train+num_val:].tolist())\n",
    "\n",
    "# Create dataframes with different splits\n",
    "df_dataset12_train = df_dataset12[df_dataset12['image_id'].isin(image_ids_train)]\n",
    "df_dataset12_val = df_dataset12[df_dataset12['image_id'].isin(image_ids_val)]\n",
    "df_dataset12_test = df_dataset12[df_dataset12['image_id'].isin(image_ids_test)]\n",
    "df_dataset3_train = df_dataset3[df_dataset3['image_id'].isin(image_ids_train)]\n",
    "df_dataset3_val = df_dataset3[df_dataset3['image_id'].isin(image_ids_val)]\n",
    "df_dataset3_test = df_dataset3[df_dataset3['image_id'].isin(image_ids_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_images_12</th>\n",
       "      <td>2315</td>\n",
       "      <td>321</td>\n",
       "      <td>635</td>\n",
       "      <td>3271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_images_3</th>\n",
       "      <td>2315</td>\n",
       "      <td>321</td>\n",
       "      <td>635</td>\n",
       "      <td>3271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_instances_12</th>\n",
       "      <td>10952</td>\n",
       "      <td>1539</td>\n",
       "      <td>2998</td>\n",
       "      <td>15489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_instances_3</th>\n",
       "      <td>12616</td>\n",
       "      <td>1768</td>\n",
       "      <td>3535</td>\n",
       "      <td>17919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train   val  test    all\n",
       "num_images_12      2315   321   635   3271\n",
       "num_images_3       2315   321   635   3271\n",
       "num_instances_12  10952  1539  2998  15489\n",
       "num_instances_3   12616  1768  3535  17919"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check image and instance counts per split\n",
    "df_split_count = pd.DataFrame(\n",
    "    [\n",
    "        [df_dataset12_train['image_id'].nunique(), df_dataset12_val['image_id'].nunique(), df_dataset12_test['image_id'].nunique()],\n",
    "        [df_dataset3_train['image_id'].nunique(), df_dataset3_val['image_id'].nunique(), df_dataset3_test['image_id'].nunique()],\n",
    "        [len(df_dataset12_train), len(df_dataset12_val), len(df_dataset12_test)],\n",
    "        [len(df_dataset3_train), len(df_dataset3_val), len(df_dataset3_test)]\n",
    "    ],\n",
    "    index=['num_images_12', 'num_images_3', 'num_instances_12', 'num_instances_3'],\n",
    "    columns=['train', 'val', 'test']\n",
    ")\n",
    "df_split_count['all'] = df_split_count.sum(axis=1)\n",
    "df_split_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save annotation datasets to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './annotations'\n",
    "dataset12_prefix = 'annotations_partial_'\n",
    "dataset3_prefix = 'annotations_complete_'\n",
    "\n",
    "df_dataset12_train.to_csv(os.path.join(output_dir, dataset12_prefix+'train.csv'))\n",
    "df_dataset12_val.to_csv(os.path.join(output_dir, dataset12_prefix+'val.csv'))\n",
    "df_dataset12_test.to_csv(os.path.join(output_dir, dataset12_prefix+'test.csv'))\n",
    "df_dataset3_train.to_csv(os.path.join(output_dir, dataset3_prefix+'train.csv'))\n",
    "df_dataset3_val.to_csv(os.path.join(output_dir, dataset3_prefix+'val.csv'))\n",
    "df_dataset3_test.to_csv(os.path.join(output_dir, dataset3_prefix+'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
