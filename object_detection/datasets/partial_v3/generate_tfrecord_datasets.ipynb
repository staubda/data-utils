{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "REPO_DIR = os.path.join(os.environ['HOME'], 'github_repos')\n",
    "\n",
    "sys.path.append(os.path.join(REPO_DIR, 'models/research/object_detection/'))\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "sys.path.append(os.path.join(REPO_DIR, 'partial-data/'))\n",
    "from partial_data.visualization import draw_bounding_boxes_on_image\n",
    "from partial_data.tfrecord import (create_label_map_pbtxt, encode_object_detection_tf_example, \n",
    "                                   decode_object_detection_tf_example, write_examples_as_tfrecord, \n",
    "                                   read_examples_from_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cats_to_mask(cats, cat_ind_map):\n",
    "    pos_inds = [cat_ind_map[cat] for cat in cats]\n",
    "    mask = np.zeros(len(cat_ind_map), dtype='bool')\n",
    "    mask[pos_inds] = True\n",
    "    return mask.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../partial_v2/annotations'\n",
    "partial_prefix = 'annotations_partial_'\n",
    "\n",
    "df_dataset_info = pd.read_json(os.path.join(input_dir, 'partial_datasets_info.json'))\n",
    "\n",
    "df_partial_train = pd.read_csv(os.path.join(input_dir, partial_prefix+'train.csv'))\n",
    "df_partial_val = pd.read_csv(os.path.join(input_dir, partial_prefix+'val.csv'))\n",
    "df_partial_test = pd.read_csv(os.path.join(input_dir, partial_prefix+'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize bounding boxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 4\n",
    "\n",
    "image_grps = df_partial_val.groupby('image_filepath')\n",
    "image_filepaths = list(image_grps.groups.keys())\n",
    "image_filepath = image_filepaths[ind]\n",
    "df_image_grp = image_grps.get_group(image_filepath)\n",
    "bboxes = df_image_grp[['hmin', 'wmin', 'hmax', 'wmax']].values\n",
    "labels = [(nm,) for nm in df_image_grp['category_name']]\n",
    "img = Image.open(image_filepath)\n",
    "font_filepath = '/home/david/github_repos/fonts/DejaVuSansMono/DejaVu Sans Mono for Powerline.ttf'\n",
    "draw_bounding_boxes_on_image(img, bboxes, \n",
    "                             font_size=18, font_filepath=font_filepath, \n",
    "                             display_str_list_list=labels)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .pbtxt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_filepath = '../partial_v2/tfrecord/label_map.pbtxt'\n",
    "label_map = label_map_util.load_labelmap(label_map_filepath)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=1000, use_display_name=True)\n",
    "cat_ind_map = {cat['name']: cat['id'] - 1 for cat in categories}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data with category mask info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign masks to image ids\n",
    "df_dataset_info['cats_mask'] = df_dataset_info['cats'].apply(lambda x: cats_to_mask(x, cat_ind_map))\n",
    "df_cats_mask = (\n",
    "    df_dataset_info\n",
    "    .drop(columns=['cats'])\n",
    "    .explode('image_ids')\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'image_ids': 'image_id'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add masks to partial datasets\n",
    "dataset_dfs = [df_partial_train, df_partial_val, df_partial_test]\n",
    "for ind, df_dataset in enumerate(dataset_dfs):\n",
    "    dataset_dfs[ind] = df_dataset.merge(df_cats_mask, on='image_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize TFRecord datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_cols = ['image_id']\n",
    "list_cols = ['wmin', 'wmax', 'hmin', 'hmax', 'category_name', 'category_id']\n",
    "first_cols = ['image_filepath', 'cats_mask']\n",
    "def get_first(vals): return vals.iloc[0]\n",
    "agg_map = {**{col: list for col in list_cols}, **{col: get_first for col in first_cols}}\n",
    "\n",
    "tfrecord_output_filepaths = [f'tfrecord/partial_{split}.record' for split in ['train', 'val', 'test']]\n",
    "\n",
    "for output_filepath, df_dataset in zip(tfrecord_output_filepaths, dataset_dfs):\n",
    "    print(output_filepath)\n",
    "    df_example = df_dataset.groupby(grp_cols).agg(agg_map).reset_index()\n",
    "    examples = [row for _, row in df_example.iterrows()]\n",
    "    write_examples_as_tfrecord(\n",
    "        examples,\n",
    "        output_filepath,\n",
    "        encode_object_detection_tf_example,\n",
    "        num_shards=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from partial_data.tf_example_decoder import TfExampleDecoder\n",
    "\n",
    "# tf_record_filepath = '/home/david/github_repos/partial-data/object_detection/datasets/partial_v2/tfrecord/complete_val.record-00000-of-00003'\n",
    "tf_record_filepath = '/home/david/github_repos/partial-data/object_detection/datasets/partial_v3/tfrecord/partial_val.record-00000-of-00003'\n",
    "# example_decoder = decode_object_detection_tf_example\n",
    "example_decoder = TfExampleDecoder().decode\n",
    "examples = read_examples_from_tfrecord(tf_record_filepath, example_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]['class_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
